# UK Bus Analytics: Current Status & Implementation Plan

**Date:** 2025-10-29
**Updated:** 2025-10-29 (Decisions Finalized)
**Project Goal:** Build modular Spatial + Temporal analytics platform demonstrating ML capabilities with UK bus data
**Implementation Strategy:** Phase 1 (Spatial) â†’ Complete â†’ Deploy â†’ Then Phase 2 (Temporal)

---

## âœ… DECISIONS MADE (Final)

### **1. Implementation Approach: Two-Phase Sequential** âœ“
- **Phase 1 FIRST:** Complete all Spatial Analytics (50 questions, 22 gaps, ML models, dashboard)
- **Phase 2 SECOND:** Add Temporal Analytics after Phase 1 deployed (11 questions, forecasting)
- **Rationale:** Deliver working product fast (7-10 days), then enhance with temporal capabilities
- **Status:** Approved âœ…
- **ğŸ†• Enhancement (2025-10-29):** Added 4 advanced economic questions + BCR/policy analysis modules

### **2. Deployment Platform: Hugging Face Spaces (FREE)** âœ“
- **Platform:** Hugging Face Spaces
- **Tier:** FREE (2 vCPUs, 16 GB RAM, 1 GB storage limit)
- **Deployment Strategy:** Aggregated data (~300 MB) NOT raw 3M stops
- **Rationale:** Free, ML-friendly, fits our scale with optimization, portfolio-ready URL
- **Status:** Approved âœ…

### **3. Data Optimization Strategy** âœ“
- **Deploy:** LSOA-aggregated metrics (7,696 rows) + pre-computed answers (~300 MB total)
- **DON'T Deploy:** Raw 3M stops (~500 MB)
- **Query Engine:** DuckDB for fast queries on aggregated data
- **ML Models:** Hugging Face caches Sentence Transformers (no repo bloat)
- **Status:** Approved âœ…

### **4. Temporal Analysis Scope (Phase 2 - Deferred)** âœ“
- **Timeline:** After Phase 1 complete and deployed
- **Historical Data:** Download Zenodo (2021-2023) + demographics when starting Phase 2
- **Scope Decision:** Will decide regional vs LSOA-level forecasting when ready
- **Status:** Deferred to Phase 2 â¸ï¸

### **5. Schools Historical Data (If Unavailable)** âœ“
- **Primary Option:** Try to get 2021-2023 schools data from GIAS
- **Fallback Option:** Use schools_2025.csv for all years (acceptable methodology)
- **Rationale:** Schools change slowly, minimal impact on temporal analysis
- **Status:** Check availability in Phase 2 â¸ï¸

---

## ğŸ“Š PROJECT STATUS SUMMARY

### **Current Position:**
```
Phase 1-3 (Foundation)   Phase 4 (Spatial ML)         Phase 5 (Temporal)
[â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ] 100% âœ… â†’ [â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘] 0% ğŸ¯ YOU ARE HERE â†’ [â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘] 0% â¸ï¸ Later
```

**Translation:** Foundation complete âœ… â†’ Ready to build Spatial ML + Dashboard â†’ Temporal deferred

### **What's Complete (Foundation Solid):**
- âœ… 3,040,885 stops processed (Oct 2025 snapshot)
- âœ… 3,578 routes catalogued
- âœ… 7,696 LSOAs with demographics integrated
- âœ… 9/9 UK regions (100% coverage)
- âœ… Data pipeline operational
- âœ… Demographics merged (Population 2021, IMD 2019, Unemployment 2024, Schools 2025)
- âœ… Basic analytics computed (regional KPIs)
- âœ… Dashboard skeleton built

### **What's NOT Complete (To Build in Phase 1):**
- âŒ 50 spatial questions systematically answered (46 original + 4 advanced economic)
- âŒ 3 ML models trained (Sentence Transformers, Isolation Forest, Random Forest)
- âŒ Economic impact models (BCR calculator, GDP multiplier, employment estimator, carbon calculator) âœ… **BUILT 2025-10-29**
- âŒ Policy scenario simulator (fare cap, frequency, coverage scenarios) âœ… **BUILT 2025-10-29**
- âŒ 6 dashboard tabs with ML integration (Coverage, Routes, Equity, ML Insights, Recommendations, Policy Briefs)
- âŒ Questions Explorer page (search 61 questions)
- âŒ Consulting Gaps showcase page (demonstrate 22 gaps - all gaps now addressed)
- âŒ NLP Q&A system (natural language interface)
- âŒ Hugging Face deployment

### **Estimate to Complete Phase 1:** 7-10 days of focused implementation

---

## ğŸš€ HUGGING FACE DEPLOYMENT STRATEGY

### Feasibility Assessment: âœ… CONFIRMED

**Hugging Face Spaces FREE Tier Limits:**
- Storage: 1 GB limit
- RAM: 16 GB
- vCPUs: 2 cores
- Persistent storage: Yes
- Public URL: âœ… https://huggingface.co/spaces/{username}/uk-bus-analytics

**Our Data Size Analysis:**
```
âŒ Raw Data (TOO LARGE for deployment):
- 3,040,885 stops Ã— 15 columns = ~500 MB
- 3,578 routes Ã— 20 columns = ~15 MB
- 7,696 LSOAs Ã— 30 columns = ~5 MB
- Historical 2021-2023 (if added) = ~1.2 GB
- TOTAL RAW: ~1.7 GB âŒ Exceeds 1 GB limit

âœ… Optimized Deployment (FITS in free tier):
- LSOA aggregated metrics (7,696 rows) = ~50 MB
- Pre-computed 46 question answers = ~20 MB
- Pre-computed visualizations (cached) = ~80 MB
- Regional summaries (9 regions) = ~5 MB
- ML model files (pickled) = ~100 MB
- Dashboard code + dependencies = ~45 MB
- TOTAL OPTIMIZED: ~300 MB âœ… Well under 1 GB
```

**Verdict:** âœ… **Hugging Face Spaces FREE tier works perfectly with aggregation strategy**

---

### Data Optimization Strategy

**1. Deploy LSOA-Aggregated Metrics (NOT Raw Stops)**

```python
# scripts/prepare_deployment_data.py

import pandas as pd
import duckdb

def aggregate_for_deployment():
    """
    Reduce 3M stops to 7,696 LSOA metrics for deployment
    Size: 500 MB â†’ 50 MB (10x reduction)
    """

    # Load raw data
    stops_raw = pd.read_parquet('data/processed/regions/*/stops_processed.parquet')

    # Aggregate by LSOA
    lsoa_metrics = stops_raw.groupby('lsoa_code').agg({
        'stop_id': 'count',
        'route_id': lambda x: x.nunique(),
        'trips_per_day': 'sum',
        'latitude': 'mean',
        'longitude': 'mean',
        'population': 'first',
        'imd_score': 'first',
        'imd_decile': 'first',
        'unemployment_rate': 'first',
        'elderly_pct': 'first',
        'car_ownership': 'first',
    }).reset_index()

    # Rename columns
    lsoa_metrics.rename(columns={
        'stop_id': 'bus_stops_count',
        'route_id': 'routes_count',
    }, inplace=True)

    # Calculate derived metrics
    lsoa_metrics['stops_per_capita'] = (
        lsoa_metrics['bus_stops_count'] / lsoa_metrics['population'] * 1000
    )
    lsoa_metrics['routes_per_capita'] = (
        lsoa_metrics['routes_count'] / lsoa_metrics['population'] * 100000
    )

    # Save as Parquet (efficient compression)
    lsoa_metrics.to_parquet(
        'deployment/data/lsoa_metrics.parquet',
        compression='snappy'
    )

    print(f"âœ… Deployment data created: {len(lsoa_metrics):,} LSOAs")
    print(f"   Size: {lsoa_metrics.memory_usage(deep=True).sum() / 1024**2:.1f} MB")

    return lsoa_metrics

# Run aggregation
if __name__ == '__main__':
    aggregate_for_deployment()
```

---

**2. Pre-Compute All Answers (Save Query Time)**

```python
# scripts/precompute_answers.py

import json
from analysis.spatial.compute_spatial_metrics import compute_all_spatial_questions

def precompute_deployment_answers():
    """
    Pre-compute answers to 46 spatial questions
    Store as JSON for instant dashboard loading
    """

    # Compute all 46 answers
    answers = compute_all_spatial_questions()

    # Structure for deployment
    deployment_answers = {
        'metadata': {
            'generated_date': '2025-10-29',
            'data_snapshot': 'October 2025',
            'total_questions': 46,
            'coverage': '9 UK regions, 7,696 LSOAs'
        },
        'answers': answers
    }

    # Save
    with open('deployment/data/spatial_answers.json', 'w') as f:
        json.dump(deployment_answers, f, indent=2)

    print(f"âœ… Pre-computed {len(answers)} question answers")

    return deployment_answers
```

---

**3. Use DuckDB for Fast Queries (No Need for Large Database)**

```python
# dashboard/utils/data_loader.py

import duckdb
import streamlit as st

@st.cache_resource
def get_duckdb_connection():
    """
    DuckDB in-memory database for fast queries
    Loads Parquet files efficiently
    """
    conn = duckdb.connect(':memory:')

    # Load LSOA metrics
    conn.execute("""
        CREATE TABLE lsoa_metrics AS
        SELECT * FROM read_parquet('deployment/data/lsoa_metrics.parquet')
    """)

    # Load regional summaries
    conn.execute("""
        CREATE TABLE regional_summary AS
        SELECT * FROM read_parquet('deployment/data/regional_summary.parquet')
    """)

    return conn

# Usage in dashboard
conn = get_duckdb_connection()
results = conn.execute("""
    SELECT region, AVG(stops_per_capita) as avg_stops
    FROM lsoa_metrics
    GROUP BY region
    ORDER BY avg_stops DESC
""").fetchdf()
```

---

**4. Cache ML Models via Hugging Face Hub (Don't Store in Repo)**

```python
# dashboard/models/ml_loader.py

from sentence_transformers import SentenceTransformer
import streamlit as st

@st.cache_resource
def load_sentence_transformer():
    """
    Load model from Hugging Face Hub (cached automatically)
    No need to store in repo
    """
    model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')
    return model

@st.cache_resource
def load_trained_models():
    """
    Load our trained models (stored in deployment/models/)
    """
    import joblib

    route_clusterer = joblib.load('deployment/models/route_clusterer.pkl')
    anomaly_detector = joblib.load('deployment/models/anomaly_detector.pkl')
    coverage_predictor = joblib.load('deployment/models/coverage_predictor.pkl')

    return {
        'route_clusterer': route_clusterer,
        'anomaly_detector': anomaly_detector,
        'coverage_predictor': coverage_predictor
    }
```

---

### Deployment File Structure

```
deployment/
â”œâ”€â”€ app.py                              # Main Streamlit app (copied from dashboard/)
â”œâ”€â”€ requirements.txt                    # Python dependencies
â”œâ”€â”€ README.md                           # Hugging Face Space description
â”œâ”€â”€ .gitattributes                      # LFS for large files
â”‚
â”œâ”€â”€ data/                               # Optimized data (~250 MB total)
â”‚   â”œâ”€â”€ lsoa_metrics.parquet           # 7,696 LSOAs (~50 MB)
â”‚   â”œâ”€â”€ regional_summary.parquet       # 9 regions (~5 MB)
â”‚   â”œâ”€â”€ spatial_answers.json           # 46 pre-computed answers (~20 MB)
â”‚   â”œâ”€â”€ consulting_gaps.json           # 22 gap demonstrations (~10 MB)
â”‚   â””â”€â”€ visualizations/                # Pre-rendered charts (~80 MB)
â”‚       â”œâ”€â”€ coverage_map.png
â”‚       â”œâ”€â”€ regional_comparison.png
â”‚       â””â”€â”€ [40+ cached visualizations]
â”‚
â”œâ”€â”€ models/                             # Trained ML models (~100 MB)
â”‚   â”œâ”€â”€ route_clusterer.pkl            # HDBSCAN model
â”‚   â”œâ”€â”€ anomaly_detector.pkl           # Isolation Forest
â”‚   â””â”€â”€ coverage_predictor.pkl         # Random Forest
â”‚
â”œâ”€â”€ pages/                              # Streamlit pages
â”‚   â”œâ”€â”€ 02_ğŸ“_Spatial_Analytics.py
â”‚   â”œâ”€â”€ 03_ğŸ“‹_Questions_Explorer.py
â”‚   â”œâ”€â”€ 04_ğŸ¯_Consulting_Gaps.py
â”‚   â””â”€â”€ 05_ğŸ’¬_Ask_Questions.py
â”‚
â””â”€â”€ utils/                              # Helper modules
    â”œâ”€â”€ data_loader.py
    â”œâ”€â”€ visualizations.py
    â””â”€â”€ ml_loader.py
```

---

### Deployment Commands

**Step 1: Prepare Optimized Data**
```bash
# Run aggregation script
python scripts/prepare_deployment_data.py

# Pre-compute answers
python scripts/precompute_answers.py

# Verify size
du -sh deployment/
# Expected: ~300 MB (well under 1 GB limit)
```

**Step 2: Create Hugging Face Space**
```bash
# Install Hugging Face CLI
pip install huggingface_hub

# Login
huggingface-cli login

# Create new Space
huggingface-cli repo create uk-bus-analytics --type space --space_sdk streamlit

# Clone the space
git clone https://huggingface.co/spaces/{your_username}/uk-bus-analytics
cd uk-bus-analytics
```

**Step 3: Deploy Files**
```bash
# Copy deployment files
cp -r deployment/* .

# Add files
git add .
git commit -m "Deploy UK Bus Analytics - Spatial Module v1.0"

# Push to Hugging Face
git push

# Wait 2-3 minutes for build
# Access at: https://huggingface.co/spaces/{your_username}/uk-bus-analytics
```

**Step 4: Configure Space Settings**
```yaml
# Create .spacesconfig.yml in repo root

title: UK Bus Analytics - ML-Powered Transport Insights
emoji: ğŸšŒ
colorFrom: blue
colorTo: green
sdk: streamlit
sdk_version: 1.28.0
app_file: app.py
pinned: true
license: mit
```

---

### Size Verification

**Before Deployment:**
```bash
# scripts/check_deployment_size.sh

#!/bin/bash

echo "ğŸ” Checking deployment size..."

# Check total size
TOTAL_SIZE=$(du -sh deployment/ | cut -f1)
echo "Total deployment size: $TOTAL_SIZE"

# Check individual folders
echo ""
echo "Breakdown:"
du -sh deployment/data/
du -sh deployment/models/
du -sh deployment/pages/

# Verify < 1 GB
SIZE_BYTES=$(du -sb deployment/ | cut -f1)
GB_LIMIT=1073741824  # 1 GB in bytes

if [ $SIZE_BYTES -lt $GB_LIMIT ]; then
    echo "âœ… Size OK: Under 1 GB limit"
    echo "   Available space: $(( ($GB_LIMIT - $SIZE_BYTES) / 1024 / 1024 )) MB"
else
    echo "âŒ Size TOO LARGE: Exceeds 1 GB limit"
    exit 1
fi
```

---

### Performance Optimizations

**1. Streamlit Caching**
```python
# Aggressive caching for fast load times

@st.cache_data(ttl=3600)  # Cache for 1 hour
def load_lsoa_data():
    return pd.read_parquet('data/lsoa_metrics.parquet')

@st.cache_resource
def load_models():
    # Models cached for entire session
    return load_trained_models()

@st.cache_data
def get_question_answer(question_id):
    # Pre-computed answers loaded once
    with open('data/spatial_answers.json') as f:
        answers = json.load(f)
    return answers['answers'][question_id]
```

**2. Lazy Loading**
```python
# Load visualizations only when needed

def show_coverage_map(region):
    # Check if cached image exists
    cache_path = f'data/visualizations/coverage_{region}.png'

    if os.path.exists(cache_path):
        st.image(cache_path)  # Instant load
    else:
        # Generate on-the-fly (first time only)
        fig = generate_coverage_map(region)
        fig.savefig(cache_path)
        st.image(cache_path)
```

---

### Expected Performance

**With Optimization:**
- Initial load time: **3-5 seconds**
- Page navigation: **<1 second**
- Question lookup: **<0.5 seconds** (pre-computed)
- Map rendering: **1-2 seconds** (cached PNGs)
- ML predictions: **<1 second** (pre-loaded models)

**User Experience:**
- âœ… Fast, responsive dashboard
- âœ… No waiting for data queries
- âœ… Smooth navigation
- âœ… Professional performance

---

## ğŸ“‹ TABLE OF CONTENTS

1. [Current Technical Progress](#current-technical-progress)
2. [Complete 57 Questions Breakdown](#complete-57-questions-breakdown)
3. [Complete 22 Consulting Gaps Breakdown](#complete-22-consulting-gaps-breakdown)
4. [What We Have NOT Built Yet](#what-we-have-not-built-yet)
5. [Phase 1 Implementation Plan (Spatial Only)](#phase-1-implementation-plan)
6. [Missing Data Download Plan](#missing-data-download-plan)
7. [Immediate Next Steps](#immediate-next-steps)

---

## ğŸ“Š CURRENT TECHNICAL PROGRESS (What We Have Built)

### âœ… Phase 1-3: COMPLETED (Data Infrastructure)

#### 1. Data Pipeline (100% Complete)
**Status:** âœ… **OPERATIONAL**

**What's Built:**
- `data_pipeline/01_data_ingestion.py` - Automated download from BODS, ONS, NOMIS
- `data_pipeline/02_data_processing.py` - TransXChange XML parsing, GTFS processing
- `data_pipeline/03_data_validation.py` - Data quality checks
- `data_pipeline/04_descriptive_analytics.py` - KPI computation

**Data Coverage:**
- âœ… 9/9 UK regions (100% coverage)
- âœ… 3,040,885 bus stops processed
- âœ… 3,578 routes catalogued
- âœ… 7,696 LSOAs with demographic integration
- âœ… October 2025 current snapshot complete

**Location:** `data/processed/regions/*/stops_processed.csv`, `routes_processed.csv`

---

#### 2. Demographics Integration (100% Complete)
**Status:** âœ… **COMPLETE**

**Datasets Integrated:**
| Dataset | Year | Status | Records |
|---------|------|--------|---------|
| Population | 2021 Census | âœ… | 33,755 LSOAs |
| IMD Deprivation | 2019 | âœ… | 32,844 LSOAs |
| Unemployment | 2024 | âœ… | 33,755 LSOAs |
| Schools | 2025 | âœ… | 24,000+ schools |
| Boundaries | 2021 | âœ… | LSOA/MSOA/LA |
| Age Structure | 2021 Census | âœ… | 33,755 LSOAs |
| Business Counts | 2024 | âœ… | Regional |

**Location:** `data/raw/demographics/`

---

#### 3. Basic Analytics (Completed)
**Status:** âœ… **OPERATIONAL**

**Scripts Built:**
- `analytics/descriptive_analysis.py` - Regional KPIs
- `analytics/05_correlation_analysis.py` - Demographic correlations
- `data_pipeline/04_descriptive_analytics.py` - 9-region analysis

**Outputs Generated:**
- `analytics/regional_summary.csv` - Regional comparison table
- `analytics/analytics_results_*.json` - Timestamped results
- `analytics/data/lsoa_analysis_results.csv` - LSOA-level metrics

**Location:** `analytics/outputs/`

---

#### 4. Basic Dashboard (Template Built)
**Status:** âš ï¸ **SKELETON BUILT - NEEDS ML INTEGRATION**

**What Exists:**
- `dashboard/app.py` - Streamlit framework
- Multi-page navigation structure
- Data loading functions
- Basic visualization templates

**What's Missing:**
- ML model integration
- 57 questions answered systematically
- Temporal analysis module
- Consulting gaps showcase

**Location:** `dashboard/`

---

#### 5. Infrastructure (Complete)
**Status:** âœ… **READY**

**Built:**
- `config/settings.py` - Configuration management
- `utils/api_client.py` - BODS, ONS, NOMIS API clients
- `utils/gtfs_parser.py` - GTFS/TransXChange parsing
- Logging system with Loguru
- Error handling & retry logic

**Location:** `config/`, `utils/`

---

## ğŸ“‹ COMPLETE 61 QUESTIONS BREAKDOWN (ENHANCED WITH ECONOMIC ANALYSIS)

### Overview: Spatial vs Temporal Split

| Category | Total Questions | **SPATIAL** (Phase 1) | **TEMPORAL** (Phase 2) |
|----------|----------------|---------------------|---------------------|
| A. Coverage & Accessibility | 8 | **8 âœ…** | 0 |
| B. Service Frequency & Reliability | 8 | **5 âœ…** | 3 âš ï¸ |
| C. Route Characteristics | 7 | **7 âœ…** | 0 |
| D. Socio-Economic Correlations | 8 | **8 âœ…** | 0 |
| E. Temporal & Trend Analysis | 5 | 0 | 5 âš ï¸ |
| F. Equity & Policy Insights | 7 | **6 âœ…** | 1 âš ï¸ |
| G. Advanced Analytical Insights | 7 | **5 âœ…** | 2 âš ï¸ |
| H. Accessibility Equity Deep Dive | 4 | **4 âœ…** | 0 |
| I. Economic Impact Analysis | 3 | **3 âœ…** | 0 |
| **J. Advanced Economic Impact (NEW âœ¨)** | **4** | **4 âœ…** | **0** |
| **TOTALS** | **61** | **50 (82%)** | **11 (18%)** |

**Phase 1 Focus:** Answer all 50 spatial questions (including 4 new advanced economic questions) before starting temporal analysis.

**ğŸ†• Enhancement (2025-10-29):** Added Category J to address consulting firm strengths in economic modeling, BCR analysis, and policy recommendations.

---

### **CATEGORY A: Coverage & Accessibility (8 Questions - ALL SPATIAL âœ…)**

**A1.** Which regions have the highest number of bus routes per capita?
**Implementation:** Aggregate routes by region, divide by population
**Data:** Oct 2025 routes + Census 2021 population
**Output:** Regional ranking table + bar chart

**A2.** Which regions have the lowest number of bus stops per 1,000 residents?
**Implementation:** Count stops by region, normalize by population
**Data:** Oct 2025 stops + Census 2021 population
**Output:** Regional ranking (ascending) + heatmap

**A3.** Are there regions where bus stop density is low relative to population density?
**Implementation:** Scatter plot: stop density vs population density, identify outliers
**Data:** Oct 2025 stops + Census 2021 population + LSOA area
**Output:** Scatter plot with outlier regions highlighted

**A4.** How many areas lack any bus service (bus deserts)?
**Implementation:** Count LSOAs with 0 bus stops
**Data:** Oct 2025 stops by LSOA
**Output:** Count + map showing bus deserts in red

**A5.** What is the average distance from a household to the nearest bus stop in each region?
**Implementation:** Haversine distance calculation, aggregate by region
**Data:** Oct 2025 stop coordinates + LSOA centroids
**Output:** Regional average distance table + distribution chart

**A6.** Which local authorities have more than 50% of residents living >500m from a bus stop?
**Implementation:** Buffer analysis (500m radius around stops), calculate population coverage
**Data:** Oct 2025 stops + LSOA population + boundaries
**Output:** List of LA with >50% uncovered + map

**A7.** How does bus coverage vary between urban and rural areas?
**Implementation:** Classify LSOAs as urban/rural, compare stop density
**Data:** Oct 2025 stops + Rural-Urban classification
**Output:** Urban vs Rural comparison table + box plot

**A8.** Are there regions where population density is high but bus services are minimal?
**Implementation:** Identify high-population-density, low-stops-per-capita LSOAs
**Data:** Oct 2025 stops + Census 2021 population
**Output:** Table of mismatched LSOAs + heatmap overlay

---

### **CATEGORY B: Service Frequency & Reliability (8 Questions - 5 SPATIAL âœ…, 3 TEMPORAL âš ï¸)**

**SPATIAL QUESTIONS (Phase 1):**

**B9.** Which regions have the highest average number of trips per day?
**Implementation:** Count trips from Oct 2025 schedules, aggregate by region
**Data:** Oct 2025 trip schedules
**Output:** Regional ranking + bar chart

**B10.** Which regions have the lowest service frequency relative to population?
**Implementation:** Trips per day / population, rank ascending
**Data:** Oct 2025 trips + Census 2021 population
**Output:** Regional ranking + scatter plot

**B12.** How many routes operate late-night or early-morning services?
**Implementation:** Parse trip times, identify services before 6am or after 11pm
**Data:** Oct 2025 stop_times
**Output:** Count + list of routes

**B15.** How does average headway (time between buses) differ across regions?
**Implementation:** Calculate headway from stop_times, aggregate by region
**Data:** Oct 2025 stop_times
**Output:** Regional average headway + distribution chart

**B16.** Are rural regions receiving proportional bus frequency relative to population?
**Implementation:** Compare urban vs rural frequency-to-population ratios
**Data:** Oct 2025 trips + Rural-Urban classification + population
**Output:** Urban vs Rural comparison + equity index

**TEMPORAL QUESTIONS (Phase 2 - Deferred):**

**B11.** Are weekend and holiday services significantly less frequent than weekdays? âš ï¸
**Requires:** Multi-day snapshot or temporal comparison
**Defer to:** Phase 2

**B13.** Which routes experience frequent cancellations or delays? âš ï¸
**Requires:** Real-time vs scheduled data over time
**Defer to:** Phase 2

**B14.** Are bus services more reliable in high-income areas than in low-income areas? âš ï¸
**Requires:** Historical reliability metrics
**Defer to:** Phase 2

---

### **CATEGORY C: Route Characteristics & Usage (7 Questions - ALL SPATIAL âœ…)**

**C17.** What is the average route length per region, and how does it correlate with population density?
**Implementation:** Calculate route lengths from shapes, correlate with population density
**Data:** Oct 2025 shapes + population
**Output:** Scatter plot + correlation coefficient

**C18.** Which routes have the highest mileage per day?
**Implementation:** Route length Ã— trips per day
**Data:** Oct 2025 routes + trips
**Output:** Top 20 routes table

**C19.** Are there overlapping routes where services could be optimized?
**Implementation:** ML clustering (Sentence Transformers + HDBSCAN) on route geometries
**Data:** Oct 2025 routes + shapes
**Output:** Cluster map + overlap analysis

**C20.** How many bus routes cross multiple local authorities?
**Implementation:** Spatial join routes with LA boundaries
**Data:** Oct 2025 routes + LA boundaries
**Output:** Count + list of cross-LA routes

**C21.** Are there regions with high population but very few inter-city routes?
**Implementation:** Identify routes crossing regional boundaries, compare to population
**Data:** Oct 2025 routes + region boundaries + population
**Output:** Regional deficit table

**C22.** Which routes are most frequently used by schools or students?
**Implementation:** Identify routes within 400m of schools, weight by school size
**Data:** Oct 2025 routes + schools 2025
**Output:** School-serving routes ranking

**C23.** Are there patterns in route usage during school hours vs. work hours?
**Implementation:** Analyze trip timing patterns (7-9am, 3-4pm school, 6-9am work)
**Data:** Oct 2025 stop_times
**Output:** Time-of-day frequency chart by route type

---

### **CATEGORY D: Socio-Economic Correlations (8 Questions - ALL SPATIAL âœ…)**

**D24.** Is there a correlation between median household income and number of bus stops per region?
**Implementation:** Pearson/Spearman correlation analysis
**Data:** Oct 2025 stops + IMD income domain
**Output:** Correlation coefficient + scatter plot

**D25.** How does unemployment rate relate to bus frequency or coverage?
**Implementation:** Correlation analysis, stratify by unemployment quartiles
**Data:** Oct 2025 stops/trips + unemployment 2024
**Output:** Correlation matrix + grouped bar chart

**D26.** Are low-income areas underserved compared to wealthier areas?
**Implementation:** Compare stops per capita in IMD decile 1 vs decile 10
**Data:** Oct 2025 stops + IMD 2019
**Output:** Decile comparison table + equity gap metric

**D27.** How does population age distribution affect bus service?
**Implementation:** Correlate elderly % with stop density (hypothesis: higher need)
**Data:** Oct 2025 stops + age structure 2021
**Output:** Age vs coverage scatter + insight

**D28.** Is there a correlation between car ownership and bus usage or route frequency?
**Implementation:** Inverse correlation expected (high car = low bus demand)
**Data:** Oct 2025 trips + IMD car ownership domain
**Output:** Correlation + regional comparison

**D29.** How does the number of schools per region correlate with bus stop distribution?
**Implementation:** Count schools and stops per region, correlate
**Data:** Oct 2025 stops + schools 2025
**Output:** Correlation + scatter plot

**D30.** Which areas with high social deprivation have low bus coverage?
**Implementation:** Filter IMD decile 1-3, identify low stops per capita
**Data:** Oct 2025 stops + IMD 2019
**Output:** Priority intervention list (top 50 LSOAs)

**D31.** Are high-density residential areas adequately served compared to commercial zones?
**Implementation:** Classify LSOAs as residential/commercial (business density), compare
**Data:** Oct 2025 stops + business counts 2024 + population
**Output:** Residential vs Commercial coverage comparison

---

### **CATEGORY E: Temporal & Trend Analysis (5 Questions - ALL TEMPORAL âš ï¸ - Phase 2)**

**E32.** How has bus service frequency changed over the past year across different socio-economic areas? âš ï¸
**Requires:** 2021-2023 Zenodo data + monthly comparison
**Defer to:** Phase 2

**E33.** Are certain regions experiencing declining service, despite population growth? âš ï¸
**Requires:** Multi-year trend analysis
**Defer to:** Phase 2

**E34.** How do seasonal patterns affect service levels (e.g., summer vs. winter)? âš ï¸
**Requires:** 12+ months seasonal data
**Defer to:** Phase 2

**E35.** Which regions have improved service coverage over time, and which have worsened? âš ï¸
**Requires:** 2021 vs 2023 comparison
**Defer to:** Phase 2

**E36.** Are there emerging underserved regions as new housing developments appear? âš ï¸
**Requires:** Historical comparison of coverage vs development
**Defer to:** Phase 2

---

### **CATEGORY F: Equity & Policy Insights (7 Questions - 6 SPATIAL âœ…, 1 TEMPORAL âš ï¸)**

**SPATIAL QUESTIONS (Phase 1):**

**F37.** Which regions should be prioritized for new routes based on low coverage + high population?
**Implementation:** Multi-criteria ranking: population > median, stops < 25th percentile
**Data:** Oct 2025 stops + Census 2021 population
**Output:** Top 20 priority LSOAs + investment map

**F38.** Where should weekend services be increased to improve accessibility?
**Implementation:** Identify areas with low weekend trip frequency + high population
**Data:** Oct 2025 weekend trips + population
**Output:** Weekend service gap map

**F39.** Which regions have the highest discrepancy between predicted vs. actual bus coverage?
**Implementation:** ML coverage prediction model (Random Forest), identify residuals
**Data:** Oct 2025 stops + demographics
**Output:** Over/under-served regions + prediction accuracy

**F40.** Are school catchment areas adequately served for student transport?
**Implementation:** 400m buffer around schools, check stop coverage
**Data:** Oct 2025 stops + schools 2025
**Output:** % schools with adequate coverage + underserved list

**F41.** Which low-income neighborhoods have limited access to public transport jobs?
**Implementation:** Identify job centers, calculate accessibility from IMD decile 1-3 areas
**Data:** Oct 2025 routes + IMD 2019 + business counts
**Output:** Employment accessibility index by deprivation

**F42.** Are rural communities underserved relative to urban areas, considering both coverage and frequency?
**Implementation:** Calculate equity index (stops per capita + trips per capita), urban vs rural
**Data:** Oct 2025 stops + trips + Rural-Urban classification
**Output:** Equity gap metric + policy recommendations

**TEMPORAL QUESTION (Phase 2 - Deferred):**

**F43.** Which regions would benefit most from new inter-city routes? âš ï¸
**Requires:** Growth pattern analysis from 2021-2023
**Defer to:** Phase 2 (Can do spatial analysis + demographic growth)

---

### **CATEGORY G: Advanced Analytical Insights (7 Questions - 5 SPATIAL âœ…, 2 TEMPORAL âš ï¸)**

**SPATIAL QUESTIONS (Phase 1):**

**G44.** Are there clusters of routes that overlap excessively, creating inefficiencies?
**Implementation:** ML clustering (Sentence Transformers + HDBSCAN on route stop sequences)
**Data:** Oct 2025 routes + stops
**Output:** Route cluster map + optimization recommendations

**G46.** Are there areas where bus stops exist but service frequency is too low to meet demand?
**Implementation:** Identify stops with <4 trips/hour + high population
**Data:** Oct 2025 stops + trips + population
**Output:** Underutilized stops list

**G47.** How does bus route connectivity affect access to healthcare, schools, or job centers?
**Implementation:** Network analysis: calculate accessibility scores to key destinations
**Data:** Oct 2025 routes + hospitals + schools + job centers
**Output:** Accessibility heatmap + connectivity index

**G48.** Which regions have potential for demand-responsive transport solutions?
**Implementation:** Identify rural/low-density areas with dispersed demand
**Data:** Oct 2025 stops + population density + rural classification
**Output:** DRT opportunity zones map

**G50.** Are there patterns in coverage that indicate transport inequality across income, age, or employment status?
**Implementation:** Multi-variate regression analysis (ML: Gradient Boosting)
**Data:** Oct 2025 stops + IMD + age + unemployment
**Output:** Inequality index + explanatory factors (SHAP values)

**TEMPORAL QUESTIONS (Phase 2 - Deferred):**

**G45.** Which regions show the largest gap between population growth and bus service growth? âš ï¸
**Requires:** 2021-2023 comparison
**Defer to:** Phase 2

**G49.** Can we predict which areas will become underserved in the next 1â€“2 years based on socio-economic trends? âš ï¸
**Requires:** Forecasting models (Prophet/TimeGPT)
**Defer to:** Phase 2

---

### **CATEGORY H: Accessibility & Equity Deep Dive (4 Questions - ALL SPATIAL âœ…)**

**H51.** Which areas have bus stops but no accessible vehicles for disabled passengers?
**Implementation:** Check GTFS wheelchair_accessible field, flag stops with no accessible routes
**Data:** Oct 2025 stops + trips (wheelchair field)
**Output:** Accessibility gap map

**H52.** How does evening/weekend service correlate with shift work patterns by income level?
**Implementation:** Analyze evening (6pm-midnight) service in manufacturing/service areas
**Data:** Oct 2025 trips + IMD employment domain + business counts
**Output:** Evening service adequacy by worker type

**H53.** Are bus routes connecting low-income areas to major employment centers?
**Implementation:** Network connectivity analysis from IMD decile 1-3 to job centers
**Data:** Oct 2025 routes + IMD 2019 + business counts
**Output:** Employment connectivity index + gap analysis

**H54.** Which areas have good coverage but poor connectivity (many stops, few destinations)?
**Implementation:** High stop count + low unique route destinations ratio
**Data:** Oct 2025 stops + routes
**Output:** Coverage vs connectivity scatter + outlier LSOAs

---

### **CATEGORY I: Economic Impact Analysis (3 Questions - ALL SPATIAL âœ…)**

**I55.** What's the correlation between bus service quality and local business density?
**Implementation:** Define service quality score, correlate with business counts
**Data:** Oct 2025 stops + trips + business counts 2024
**Output:** Correlation + service quality index

**I56.** How does transport accessibility affect property values across income brackets?
**Implementation:** Accessibility score vs property prices (from IMD income domain proxy)
**Data:** Oct 2025 stops + IMD income domain
**Output:** Accessibility premium estimate

**I57.** Which underserved areas have the highest potential economic impact from improved services?
**Implementation:** BCR calculation: investment cost vs economic multiplier benefits
**Data:** Oct 2025 stops + population + business counts + IMD
**Output:** BCR ranking of investment opportunities

---

### **CATEGORY J: Advanced Economic Impact Analysis (4 Questions - ALL SPATIAL âœ… NEW âœ¨)**

**ğŸ†• Added 2025-10-29 to address consulting firm gaps in economic modeling**

**J58.** What is the Benefit-Cost Ratio (BCR) for investing Â£10M in the top 10 underserved LSOAs?
**Implementation:** UK Treasury Green Book methodology with 30-year appraisal
**Data:** Oct 2025 stops + population + IMD + unemployment
**Benefit Components:**
- Time savings (DfT values: Â£25.19/hour commuting, Â£12.85/hour leisure)
- Carbon savings (BEIS: Â£250/tonne CO2)
- Health benefits (air quality + active travel)
- Agglomeration effects (economic density)
- Employment access (job connectivity)
- Accident reduction (road safety)
- Tax revenue impacts
**Output:** BCR, NPV, cost/benefit breakdown, investment priority ranking
**Implementation File:** `analysis/spatial/utils/bcr_calculator.py`

**J59.** What is the estimated GDP multiplier effect of improved bus service in deprived areas?
**Implementation:** ONS regional input-output modeling
**Data:** Oct 2025 investment + business counts + regional multipliers
**GDP Impact Components:**
- Direct GDP (65% of investment)
- Indirect GDP (supply chain effects: 45%)
- Induced GDP (household spending: 35%)
- Business productivity gains (Â£2.5k per business)
- Employment income (new jobs created)
- Agglomeration GDP (25% for deprived areas)
**Output:** GDP multiplier (Â£X generated per Â£1 invested), regional GDP breakdown
**Implementation File:** `analysis/spatial/04_economic_impact_modeling.py`

**J60.** How many jobs would be created by expanding service frequency by 20% nationwide?
**Implementation:** Employment multiplier analysis (direct + indirect + induced)
**Data:** Oct 2025 routes + trips + ONS employment multipliers
**Job Categories:**
- Direct: Bus drivers, supervisors
- Indirect: Mechanics, admin, manufacturing, fuel supply
- Induced: Retail, hospitality (multiplier effect)
**Output:** Total jobs, job type breakdown, regional distribution, income generated, tax revenue
**Implementation File:** `analysis/spatial/04_economic_impact_modeling.py`

**J61.** What is the carbon emissions reduction potential from modal shift to buses?
**Implementation:** BEIS greenhouse gas conversion factors + 30-year appraisal
**Data:** Oct 2025 stops + population coverage + BEIS carbon values (2025)
**Scenarios:**
- Optimistic: 15% modal shift
- Realistic: 8% modal shift
- Conservative: 4% modal shift
**Emissions:**
- Car: 0.171 kg CO2/km
- Bus: 0.089 kg CO2/passenger-km
**Output:** CO2 saved (tonnes/year), carbon value (Â£), equivalent cars off road, air quality benefits
**Implementation File:** `analysis/spatial/04_economic_impact_modeling.py`

---

## ğŸ¯ COMPLETE 22 CONSULTING GAPS BREAKDOWN

### Overview: Spatial vs Temporal Split

| Gap Category | Total Gaps | **SPATIAL** (Phase 1) | **TEMPORAL** (Phase 2) |
|--------------|-----------|---------------------|---------------------|
| ğŸ¤– Technical Innovation | 5 | **3 âœ…** | 2 âš ï¸ |
| ğŸ”„ Data Processing | 3 | **3 âœ…** | 0 |
| ğŸ—ºï¸ User Interface | 3 | **3 âœ…** | 0 |
| ğŸ“Š Analytics Capability | 5 | **4 âœ…** | 1 âš ï¸ |
| âš¡ Operational Intelligence | 4 | **1 âœ…** | 3 âš ï¸ |
| ğŸš€ System Architecture | 2 | **2 âœ…** | 0 |
| **ğŸ’° Economic & Policy Analysis (NEW âœ¨)** | **6** | **6 âœ…** | **0** |
| **TOTALS** | **28** | **22 (79%)** | **6 (21%)** |

**Phase 1 Focus:** Implement all 22 spatial gaps (including 6 new economic/policy gaps) before starting temporal analysis.

**ğŸ†• Enhancement (2025-10-29):** Added 6 economic/policy gaps to address consulting firm strengths:
- Gap 23: UK Treasury Green Book BCR Analysis âœ…
- Gap 24: ONS GDP Multiplier Modeling âœ…
- Gap 25: Employment Impact Assessment âœ…
- Gap 26: BEIS Carbon Benefit Quantification âœ…
- Gap 27: Policy Scenario Simulation âœ…
- Gap 28: Automated Policy Brief Generation âœ…

---

### **ğŸ¤– TECHNICAL INNOVATION GAPS (5 Total - 3 Spatial âœ…, 2 Temporal âš ï¸)**

**GAP 1: Pre-trained ML Model Integration (Hugging Face) âœ… SPATIAL**

**What Consulting Reports Have:** Traditional statistical methods only (averages, percentages, basic regression)

**What We Provide:** Multiple Hugging Face pre-trained models for transport analytics

**Implementation (Phase 1):**
- Sentence Transformers (`all-MiniLM-L6-v2`) for route text embeddings
- Zero-shot classification for route categorization
- Pre-trained embeddings for similarity analysis

**Files to Create:**
```python
# analysis/spatial/02_train_ml_models.py
from sentence_transformers import SentenceTransformer

model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')
route_embeddings = model.encode(route_descriptions)
```

**Dashboard Integration:** "ML Insights" page showing route clusters

**Value:** State-of-the-art NLP applied to transport planning

---

**GAP 2: Route Embeddings using Sentence Transformers âœ… SPATIAL**

**What Consulting Reports Have:** Basic route analysis without ML (manually defined categories)

**What We Provide:** Intelligent route similarity clustering via embeddings

**Implementation (Phase 1):**
```python
# Route similarity analysis
from sentence_transformers import SentenceTransformer
from hdbscan import HDBSCAN

# Create route descriptions
routes['description'] = routes.apply(lambda r:
    f"Route {r['route_id']}: {r['route_name']}. "
    f"Operator: {r['operator']}. Stops: {r['stop_sequence']}", axis=1)

# Generate embeddings
model = SentenceTransformer('all-MiniLM-L6-v2')
embeddings = model.encode(routes['description'].tolist())

# Cluster
clusterer = HDBSCAN(min_cluster_size=5)
routes['cluster'] = clusterer.fit_predict(embeddings)
```

**Output:** Route cluster map + optimization recommendations (consolidate similar routes)

**Value:** Data-driven route network optimization

---

**GAP 3: Natural Language Query System (LLM-powered) âœ… SPATIAL**

**What Consulting Reports Have:** Static PDF reports, no interactive querying

**What We Provide:** Conversational interface for data exploration

**Implementation (Phase 1):**
```python
# Semantic Q&A system (no expensive LLM needed)
qa_model = SentenceTransformer('all-MiniLM-L6-v2')

# Pre-compute answers to 46 spatial questions
qa_database = {
    "Which regions have lowest coverage?": {
        "answer": "West Midlands (51 stops/LSOA), East Midlands (63 stops/LSOA)",
        "data": regional_stats,
        "visualization": "coverage_map.png"
    },
    # ... 45 more questions
}

# Semantic search for user queries
def answer_question(user_query):
    query_emb = qa_model.encode(user_query)
    question_embs = qa_model.encode(list(qa_database.keys()))
    similarity = cosine_similarity(query_emb, question_embs)
    best_match = qa_database[list(qa_database.keys())[similarity.argmax()]]
    return best_match
```

**Dashboard Page:** "Ask Questions" with text input + search

**Value:** Democratizes data access for non-technical stakeholders

---

**GAP 4: Advanced Time-Series Forecasting (TimeGPT) âš ï¸ TEMPORAL - Phase 2**

**Defer to Phase 2:** Requires 2021-2023 historical data (Zenodo)

---

**GAP 5: Automated Anomaly Detection âš ï¸ TEMPORAL - Phase 2**

**Defer to Phase 2:** Temporal anomalies require historical baseline

**Note:** Spatial anomaly detection (Gap 14) is implemented in Phase 1

---

### **ğŸ”„ DATA PROCESSING GAPS (3 Total - ALL SPATIAL âœ…)**

**GAP 6: Real-time GTFS Data Processing Pipeline âœ… SPATIAL**

**What Consulting Reports Have:** Historical data focus (outdated reports)

**What We Provide:** Live data feeds with current snapshot (Oct 2025)

**Implementation (Already Built):**
- `data_pipeline/01_data_ingestion.py` - Automated BODS API downloads
- `data_pipeline/02_data_processing.py` - TransXChange/GTFS parsing
- Scheduled updates capability (cron jobs)

**Value:** Up-to-date insights vs 6-12 month old consulting reports

---

**GAP 7: Automated ETL with Scheduled Updates âœ… SPATIAL**

**What Consulting Reports Have:** Manual data processing (labor-intensive)

**What We Provide:** Automated Prefect/GitHub Actions workflows

**Implementation (Already Built):**
- `data_pipeline/` scripts with error handling
- `config/settings.py` for configuration
- `utils/api_client.py` with retry logic

**Future Enhancement:** GitHub Actions workflow for monthly runs

**Value:** Continuous monitoring vs periodic manual reports

---

**GAP 8: Multi-source Data Integration âœ… SPATIAL**

**What Consulting Reports Have:** Basic data combination (siloed datasets)

**What We Provide:** Seamless BODS + ONS + IMD + Schools integration

**Implementation (Already Built):**
- 7 demographic datasets merged by LSOA
- Transport + socioeconomic unified analysis
- 3M+ stops with demographic attributes

**Value:** Holistic view of transport-society interactions

---

### **ğŸ—ºï¸ USER INTERFACE GAPS (3 Total - ALL SPATIAL âœ…)**

**GAP 9: Interactive Multi-layer Geospatial Mapping âœ… SPATIAL**

**What Consulting Reports Have:** Static choropleth maps (PDF images)

**What We Provide:** Folium/Plotly interactive maps with toggleable demographic layers

**Implementation (Phase 1):**
```python
# dashboard/components/maps.py
import folium
from streamlit_folium import st_folium

m = folium.Map(location=[54.0, -2.0], zoom_start=6)

# Layer 1: Bus stops
stops_layer = folium.FeatureGroup(name='Bus Stops')
for _, stop in stops.iterrows():
    folium.CircleMarker([stop['lat'], stop['lon']],
                       radius=3, color='blue').add_to(stops_layer)

# Layer 2: IMD deprivation heatmap
deprivation_layer = folium.Choropleth(
    geo_data=lsoa_boundaries,
    data=imd_data,
    columns=['lsoa_code', 'imd_score'],
    key_on='feature.properties.lsoa_code',
    fill_color='YlOrRd',
    legend_name='IMD Deprivation Score'
)

# Add layer controls
stops_layer.add_to(m)
deprivation_layer.add_to(m)
folium.LayerControl().add_to(m)

st_folium(m, width=1200, height=600)
```

**Dashboard Pages:** Coverage Analysis, Equity Analysis

**Value:** Superior visualization + exploration capability

---

**GAP 10: Dynamic Multi-dimensional Filtering âœ… SPATIAL**

**What Consulting Reports Have:** Simple filtering (one variable at a time)

**What We Provide:** Filter by region AND income AND unemployment simultaneously

**Implementation (Phase 1):**
```python
# dashboard/components/filters.py
import streamlit as st

col1, col2, col3 = st.columns(3)

with col1:
    selected_regions = st.multiselect('Region', options=regions)

with col2:
    income_range = st.slider('IMD Income Decile', 1, 10, (1, 10))

with col3:
    unemployment_range = st.slider('Unemployment %', 0.0, 20.0, (0.0, 20.0))

# Filter data
filtered_data = data[
    (data['region'].isin(selected_regions)) &
    (data['imd_decile'].between(*income_range)) &
    (data['unemployment'].between(*unemployment_range))
]
```

**Dashboard Pages:** All spatial analysis pages

**Value:** Complex multi-dimensional analysis capability

---

**GAP 11: Conversational Analytics Interface âœ… SPATIAL**

**What Consulting Reports Have:** No interactive query capability

**What We Provide:** Natural language questioning of data

**Implementation:** See Gap 3 (Natural Language Query System)

**Value:** Accessible analytics for all stakeholders

---

### **ğŸ“Š ANALYTICS CAPABILITY GAPS (5 Total - 4 Spatial âœ…, 1 Temporal âš ï¸)**

**GAP 12: ML-powered Route Clustering âœ… SPATIAL**

**What Consulting Reports Have:** No intelligent clustering (manual categories)

**What We Provide:** K-Means/HDBSCAN on route embeddings

**Implementation:** See Gap 2 (Route Embeddings)

**Value:** Data-driven route network optimization

---

**GAP 13: Automated Correlation Analysis âœ… SPATIAL**

**What Consulting Reports Have:** Manual ad-hoc correlations

**What We Provide:** Systematic mapping of ALL variable relationships

**Implementation (Phase 1):**
```python
# analysis/spatial/01_compute_spatial_metrics.py
import pandas as pd
from scipy.stats import pearsonr, spearmanr

# Compute all pairwise correlations
variables = ['bus_stops', 'routes', 'population', 'imd_score',
             'unemployment', 'age_65plus', 'car_ownership']

correlation_matrix = pd.DataFrame(index=variables, columns=variables)

for var1 in variables:
    for var2 in variables:
        corr, pval = pearsonr(data[var1], data[var2])
        correlation_matrix.loc[var1, var2] = f"{corr:.3f} (p={pval:.3f})"

# Save
correlation_matrix.to_csv('data/processed/spatial/correlation_matrix.csv')
```

**Dashboard:** Equity Analysis page with correlation heatmap

**Value:** Systematic identification of all relationships

---

**GAP 14: AI-powered Underserved Area Identification âœ… SPATIAL**

**What Consulting Reports Have:** Manual expert judgment

**What We Provide:** ML identifies service gaps automatically (Isolation Forest)

**Implementation (Phase 1):**
```python
# analysis/spatial/02_train_ml_models.py
from sklearn.ensemble import IsolationForest
from sklearn.preprocessing import StandardScaler

# Features for anomaly detection
features = ['population', 'bus_stops', 'routes', 'imd_score',
            'unemployment', 'elderly_pct']
X = lsoa_data[features].fillna(lsoa_data[features].median())

# Standardize
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# Detect spatial anomalies (underserved areas)
iso_forest = IsolationForest(contamination=0.05, random_state=42)
lsoa_data['is_underserved'] = iso_forest.fit_predict(X_scaled)

# Flag areas: high population + low stops + high deprivation
underserved = lsoa_data[
    (lsoa_data['is_underserved'] == -1) &
    (lsoa_data['population'] > lsoa_data['population'].median()) &
    (lsoa_data['imd_decile'] <= 3)
]

# Save
underserved.to_parquet('data/processed/spatial/underserved_areas.parquet')
```

**Dashboard:** ML Insights page + Policy Recommendations

**Value:** Automated identification of service gaps

---

**GAP 15: Prescriptive Analytics for Route Optimization âœ… SPATIAL**

**What Consulting Reports Have:** General recommendations only

**What We Provide:** ML-generated route improvement suggestions

**Implementation (Phase 1):**
```python
# analysis/spatial/03_generate_recommendations.py

def generate_recommendations(lsoa_data, route_clusters):
    recommendations = []

    # Recommendation 1: New route needed
    high_priority = lsoa_data[
        (lsoa_data['population'] > 5000) &
        (lsoa_data['bus_stops'] < 5) &
        (lsoa_data['imd_decile'] <= 3)
    ]

    for _, lsoa in high_priority.iterrows():
        recommendations.append({
            'lsoa_code': lsoa['lsoa_code'],
            'type': 'new_route',
            'priority': 'HIGH',
            'rationale': f"High population ({lsoa['population']:,}), "
                        f"low stops ({lsoa['bus_stops']}), "
                        f"deprived area (IMD decile {lsoa['imd_decile']})",
            'estimated_cost': estimate_route_cost(lsoa),
            'estimated_benefit': estimate_bcr(lsoa)
        })

    # Recommendation 2: Route consolidation (from clustering)
    for cluster_id, routes in route_clusters.items():
        if len(routes) >= 3:  # 3+ similar routes
            recommendations.append({
                'type': 'consolidate_routes',
                'routes': routes,
                'priority': 'MEDIUM',
                'rationale': f"Routes {routes} have 85%+ overlap, "
                            f"consolidation could improve efficiency",
                'estimated_savings': estimate_consolidation_savings(routes)
            })

    return pd.DataFrame(recommendations)
```

**Dashboard:** Policy Recommendations page with actionable insights

**Value:** Actionable recommendations for improvement

---

**GAP 16: Real-time Service Quality Monitoring âš ï¸ TEMPORAL - Phase 2**

**Defer to Phase 2:** Requires ongoing monitoring infrastructure

---

### **âš¡ OPERATIONAL INTELLIGENCE & PREDICTIVE ANALYTICS GAPS (4 Total - 1 Spatial âœ…, 3 Temporal âš ï¸)**

**GAP 17: Live Dashboards âœ… SPATIAL**

**What Consulting Reports Have:** Static PDFs

**What We Provide:** Interactive Streamlit dashboard

**Implementation (Phase 1):** All dashboard pages with real-time filtering

**Value:** Interactive exploration vs static documents

---

**GAPS 18-20: Automated Insights, Predictive Disruption, Granular Forecasting âš ï¸ TEMPORAL - Phase 2**

**Defer to Phase 2:** All require temporal/forecasting models

---

### **ğŸš€ SYSTEM ARCHITECTURE GAPS (2 Total - ALL SPATIAL âœ…)**

**GAP 21: End-to-end ML Deployment Pipeline âœ… SPATIAL**

**What Consulting Reports Have:** Traditional static reporting

**What We Provide:** Modern deployment (Streamlit â†’ Hugging Face Spaces)

**Implementation (Phase 1):**
- ML model training scripts
- Model persistence (pickle/joblib)
- Dashboard integration
- Cloud deployment

**Value:** Production-ready ML system

---

**GAP 22: Cloud-based Scalable Architecture âœ… SPATIAL**

**What Consulting Reports Have:** Desktop-only analysis tools

**What We Provide:** Web-based accessible anywhere

**Implementation (Phase 1):**
- Parquet for efficient storage
- DuckDB for fast queries
- Streamlit caching
- Hugging Face Spaces deployment

**Value:** Scalable, accessible, cloud-native

---

### **ğŸ’° ECONOMIC & POLICY ANALYSIS GAPS (6 Total - ALL SPATIAL âœ… NEW âœ¨)**

**ğŸ†• Added 2025-10-29 to address consulting firm strengths**

**GAP 23: UK Treasury Green Book BCR Analysis âœ… SPATIAL**

**What Consulting Reports Have:** Comprehensive BCR analysis following UK Treasury methodology

**What We NOW Provide:** Full BCR calculator with 30-year appraisal

**Implementation (Phase 1 - COMPLETED 2025-10-29):**
```python
# analysis/spatial/utils/bcr_calculator.py
class BCRCalculator:
    - 7 benefit components (time savings, carbon, health, agglomeration, employment, accidents, tax)
    - DfT TAG 2025 appraisal values
    - 30-year discounted cash flow (3.5% discount rate)
    - Present value calculations
    - BCR, NPV, and recommendation outputs
```

**Value:** Government-ready economic appraisal (matches consulting report standards)

---

**GAP 24: ONS GDP Multiplier Modeling âœ… SPATIAL**

**What Consulting Reports Have:** Regional economic impact analysis with GDP multipliers

**What We NOW Provide:** ONS input-output table methodology for GDP calculation

**Implementation (Phase 1 - COMPLETED 2025-10-29):**
```python
# analysis/spatial/04_economic_impact_modeling.py
def j59_gdp_multiplier_analysis():
    - Direct GDP (65% of investment)
    - Indirect GDP (supply chain: 45%)
    - Induced GDP (household spending: 35%)
    - Business productivity gains
    - Agglomeration effects (25% for deprived areas)
    - Regional breakdown
```

**Value:** Quantify economic ripple effects (typically 1.5-2.5x multiplier for transport)

---

**GAP 25: Employment Impact Assessment âœ… SPATIAL**

**What Consulting Reports Have:** Job creation estimates with detailed breakdowns

**What We NOW Provide:** Direct, indirect, and induced employment calculations

**Implementation (Phase 1 - COMPLETED 2025-10-29):**
```python
# analysis/spatial/04_economic_impact_modeling.py
def j60_employment_impact_analysis():
    - Direct jobs (drivers, supervisors)
    - Indirect jobs (mechanics, manufacturing, supply chain)
    - Induced jobs (retail, hospitality from multiplier effect)
    - Regional distribution
    - Income and tax revenue generated
```

**Value:** Quantify job creation for policy planning (employment multiplier ~2.1x)

---

**GAP 26: BEIS Carbon Benefit Quantification âœ… SPATIAL**

**What Consulting Reports Have:** Carbon savings monetized using government values

**What We NOW Provide:** BEIS greenhouse gas conversion factors with 30-year appraisal

**Implementation (Phase 1 - COMPLETED 2025-10-29):**
```python
# analysis/spatial/04_economic_impact_modeling.py
def j61_carbon_reduction_analysis():
    - 3 scenarios (optimistic 15%, realistic 8%, conservative 4% modal shift)
    - Car emissions: 0.171 kg CO2/km
    - Bus emissions: 0.089 kg CO2/passenger-km
    - Carbon value: Â£250/tonne (BEIS 2025)
    - 30-year carbon value calculation
    - Air quality and noise reduction benefits
```

**Value:** Environmental benefit monetization for Net Zero 2050 alignment

---

**GAP 27: Policy Scenario Simulation âœ… SPATIAL**

**What Consulting Reports Have:** Static single-scenario analysis

**What We NOW Provide:** Interactive "what-if" policy simulator

**Implementation (Phase 1 - COMPLETED 2025-10-29):**
```python
# analysis/spatial/05_policy_scenario_simulator.py
class PolicyScenarioSimulator:
    - Fare cap scenarios (Â£1, Â£2, Â£3)
    - Frequency increase scenarios (10%, 20%, 30%)
    - Coverage expansion scenarios (5%, 10%, 15%)
    - Combined multi-policy analysis
    - Elasticity-based ridership modeling
    - BCR calculation for each scenario
    - Synergy effects (15% interaction factor)
```

**Value:** Real-time policy analysis (consulting reports: weeks of manual work)

---

**GAP 28: Automated Policy Brief Generation âœ… SPATIAL**

**What Consulting Reports Have:** Manual drafting of government reports (labor-intensive)

**What We Provide:** Auto-generated policy briefs from ML insights

**Implementation (Phase 1 - Dashboard Integration):**
```python
# dashboard/pages/06_ğŸ“‹_Policy_Briefs.py (To be built)
- Select region + intervention type
- Auto-generate 2-page PDF:
    - Problem statement (ML-detected underserved areas)
    - Proposed solution
    - Economic analysis (BCR, GDP, jobs, carbon)
    - Funding requirements
    - Implementation timeline
```

**Value:** Instant government-ready reports (consulting: Â£50k+ per report, 4-6 weeks)

---

## âŒ WHAT WE HAVE NOT BUILT YET (To-Do - Phase 1 Focus)

### Phase 4: SPATIAL ANALYTICS MODULE (Not Started)

#### 1. ML Model Implementation
**Status:** âš ï¸ **PARTIALLY COMPLETE**

**Need to Build:**
```
analysis/spatial/
â”œâ”€â”€ 01_compute_spatial_metrics.py     # Answer 50 spatial questions (46 + 4 economic)
â”œâ”€â”€ 02_train_ml_models.py              # Train 3 ML models:
â”‚   â”œâ”€â”€ Route clustering (Sentence Transformers + HDBSCAN)
â”‚   â”œâ”€â”€ Underserved area detection (Isolation Forest)
â”‚   â””â”€â”€ Coverage prediction (Random Forest)
â”œâ”€â”€ 03_generate_recommendations.py     # Policy recommendations
â”œâ”€â”€ 04_economic_impact_modeling.py     # âœ… BUILT 2025-10-29 (Category J: J58-J61)
â”œâ”€â”€ 05_policy_scenario_simulator.py    # âœ… BUILT 2025-10-29 (Fare/frequency/coverage)
â””â”€â”€ utils/
    â””â”€â”€ bcr_calculator.py               # âœ… BUILT 2025-10-29 (UK Treasury Green Book)
```

**Models to Train:**
- âŒ Sentence Transformers for route embeddings
- âŒ HDBSCAN clustering on route embeddings
- âŒ Isolation Forest for spatial anomaly detection
- âŒ Random Forest for coverage prediction
- âŒ Prescriptive recommendation engine

**Dependencies:**
```bash
pip install sentence-transformers hdbscan umap-learn scikit-learn
```

**Estimated Time:** 2-3 days

---

#### 2. Spatial Dashboard Pages
**Status:** âŒ **NOT BUILT**

**Need to Create:**
```
dashboard/pages/
â”œâ”€â”€ 02_ğŸ“_Spatial_Analytics.py         # Main spatial page with tabs:
â”‚   â”œâ”€â”€ Tab 1: Coverage Analysis
â”‚   â”œâ”€â”€ Tab 2: Route Characteristics
â”‚   â”œâ”€â”€ Tab 3: Socio-Economic Equity
â”‚   â”œâ”€â”€ Tab 4: ML-Powered Insights
â”‚   â””â”€â”€ Tab 5: Policy Recommendations
â”‚
dashboard/modules/spatial/
â”œâ”€â”€ coverage.py                        # Coverage analysis logic
â”œâ”€â”€ routes.py                          # Route analysis logic
â”œâ”€â”€ equity.py                          # Equity analysis logic
â”œâ”€â”€ ml_insights.py                     # ML model results display
â””â”€â”€ recommendations.py                 # Policy recommendation generator
```

**Estimated Time:** 3-4 days

---

#### 3. 46 Spatial Questions - Systematic Answers
**Status:** âŒ **NOT SYSTEMATICALLY ANSWERED**

**Need to Compute:**
- Coverage & Accessibility (8 questions)
- Service Frequency & Reliability (6 questions - spatial subset)
- Route Characteristics (7 questions)
- Socio-Economic Correlations (8 questions)
- Equity & Policy (6 questions - spatial subset)
- Advanced Insights (5 questions - spatial subset)
- Accessibility Deep Dive (4 questions)
- Economic Impact (3 questions)

**Output Format:**
```json
{
  "question_id": "A1",
  "question": "Which regions have highest routes per capita?",
  "answer": {
    "summary": "South East leads with 45.2 routes per 100k residents",
    "data": [...],
    "visualization": "path/to/chart.png",
    "insights": ["Key finding 1", "Key finding 2"]
  }
}
```

**Estimated Time:** 2-3 days

---

### Phase 5: TEMPORAL ANALYTICS MODULE (Not Started)

#### 1. Historical Data Acquisition
**Status:** âŒ **NOT DOWNLOADED**

**Need to Download:**

**A. Zenodo Transport Archive:**
- Size: 19.5 GB
- Content: 2021-2023 bus stops, routes, trips (bi-weekly snapshots)
- URL: https://zenodo.org/records/14779119/files/bods_archive_jun2023.zip
- Time: 30-60 min download + 2-3 hours processing

**B. Missing Demographics for 2021-2023:**

| Dataset | Years Needed | Source | Status |
|---------|--------------|--------|--------|
| Population | 2022, 2023 | ONS Mid-Year Estimates | âŒ Need to download |
| Unemployment | 2021, 2022, 2023 | NOMIS API | âŒ Need to download |
| Schools | 2021, 2022, 2023 | GIAS historical (if available) | âŒ Check availability |

**Scripts to Create:**
```bash
scripts/
â”œâ”€â”€ download_zenodo.sh                 # Download 2021-2023 transport data
â”œâ”€â”€ download_historical_demographics.py # Get population, unemployment 2021-2023
â””â”€â”€ check_schools_historical.py        # Check if school data available
```

**Estimated Time:** 1 day

---

#### 2. Time-Series Data Processing
**Status:** âŒ **NOT BUILT**

**Need to Create:**
```
analysis/temporal/
â”œâ”€â”€ 01_process_zenodo_archive.py       # Parse 104 snapshots â†’ structured format
â”œâ”€â”€ 02_create_timeseries.py            # Aggregate to monthly LSOA metrics
â”œâ”€â”€ 03_train_forecasting_models.py     # Train Prophet/TimeGPT models
â””â”€â”€ 04_detect_anomalies.py             # Temporal anomaly detection
```

**Output Structure:**
```python
# Target: data/processed/temporal/timeseries_2021_2023.parquet
# Columns: [snapshot_date, lsoa_code, bus_stops, routes, trips_per_day,
#           population, unemployment, imd_score, ...]
# Rows: 30 months Ã— 7,696 LSOAs = ~230,000 rows
```

**Estimated Time:** 2-3 days

---

#### 3. Temporal ML Models
**Status:** âŒ **NOT BUILT**

**Need to Train:**
- âŒ Prophet forecasting models (1 per LSOA or regional aggregates)
- âŒ Temporal anomaly detection (Isolation Forest on trends)
- âŒ Change-point detection (PELT algorithm)
- âŒ Trend analysis (Mann-Kendall tests)

**Dependencies:**
```bash
pip install prophet ruptures pymannkendall
```

**Estimated Time:** 2-3 days

---

#### 4. Temporal Dashboard Pages
**Status:** âŒ **NOT BUILT**

**Need to Create:**
```
dashboard/pages/
â”œâ”€â”€ 03_â±ï¸_Temporal_Analytics.py        # Main temporal page with tabs:
â”‚   â”œâ”€â”€ Tab 1: Trend Analysis (2021-2023)
â”‚   â”œâ”€â”€ Tab 2: Forecasting (Prophet models)
â”‚   â”œâ”€â”€ Tab 3: Anomaly Detection (service drops)
â”‚   â””â”€â”€ Tab 4: Historical Comparison (2021 vs 2023)
â”‚
dashboard/modules/temporal/
â”œâ”€â”€ trends.py                          # Trend analysis logic
â”œâ”€â”€ forecasting.py                     # Prophet model predictions
â”œâ”€â”€ anomalies.py                       # Anomaly detection results
â””â”€â”€ comparison.py                      # Year-over-year comparison
```

**Banner to Add:**
```
âš ï¸ TEMPORAL ANALYSIS: Using 2021-2023 historical research data (Zenodo archive).
   Live data collection started October 2025 for extended analysis.
```

**Estimated Time:** 3-4 days

---

#### 5. 11 Temporal Questions - Answers
**Status:** âŒ **NOT ANSWERED**

**Need to Compute:**
- Temporal & Trend Analysis (5 questions)
- Service reliability over time (2 questions)
- Historical comparison insights (4 questions)

**Estimated Time:** 1-2 days

---

### Phase 6: INTEGRATION & SHOWCASE (Not Started)

#### 1. 57 Questions Explorer Page
**Status:** âŒ **NOT BUILT**

**Need to Create:**
```
dashboard/pages/
â””â”€â”€ 04_ğŸ“‹_Questions_Explorer.py
    â”œâ”€â”€ Search box (full-text search)
    â”œâ”€â”€ Category filter (A-I categories)
    â”œâ”€â”€ Spatial/Temporal toggle
    â”œâ”€â”€ Question cards with:
    â”‚   â”œâ”€â”€ Question text
    â”‚   â”œâ”€â”€ Answer summary
    â”‚   â”œâ”€â”€ Visualization
    â”‚   â””â”€â”€ Export button
    â””â”€â”€ Bulk export functionality
```

**Data Structure:**
```json
{
  "questions": [
    {
      "id": "A1",
      "category": "Coverage & Accessibility",
      "type": "spatial",
      "question": "Which regions have highest routes per capita?",
      "answer": {...},
      "visualization": "chart.png"
    },
    ...
  ]
}
```

**Estimated Time:** 2 days

---

#### 2. Consulting Gaps Showcase Page
**Status:** âŒ **NOT BUILT**

**Need to Create:**
```
dashboard/pages/
â””â”€â”€ 05_ğŸ¯_Consulting_Gaps.py
    â”œâ”€â”€ Gap matrix table (22 capabilities)
    â”œâ”€â”€ Side-by-side comparison:
    â”‚   â”œâ”€â”€ Traditional reports (what they lack)
    â”‚   â””â”€â”€ This project (what we have)
    â”œâ”€â”€ Live demos for each capability
    â””â”€â”€ ROI/Impact explanations
```

**Content:**
- 22 gaps from reports.md gap analysis
- Interactive demos of each capability
- Evidence that consulting firms don't have this

**Estimated Time:** 2 days

---

#### 3. Natural Language Q&A System
**Status:** âŒ **NOT BUILT**

**Need to Create:**
```
dashboard/pages/
â””â”€â”€ 06_ğŸ’¬_Ask_Questions.py
    â”œâ”€â”€ Text input box
    â”œâ”€â”€ Semantic search (Sentence Transformers)
    â”œâ”€â”€ Pre-computed Q&A database (57 questions)
    â”œâ”€â”€ Answer display with sources
    â””â”€â”€ "Ask follow-up" functionality
```

**Implementation Approach:**
```python
# Semantic search Q&A (no LLM needed - cost-effective)
model = SentenceTransformer('all-MiniLM-L6-v2')
qa_database = load_57_questions_answers()
question_embeddings = model.encode(qa_database.keys())

def answer_question(user_query):
    query_emb = model.encode(user_query)
    similarities = cosine_similarity(query_emb, question_embeddings)
    best_match = qa_database[similarities.argmax()]
    return best_match
```

**Estimated Time:** 2 days

---

### Phase 7: DEPLOYMENT & DOCUMENTATION (Not Started)

#### 1. Deployment to Hugging Face Spaces
**Status:** âŒ **NOT DEPLOYED**

**Need to Do:**
- Create Hugging Face account/Space
- Optimize data files (<1 GB for free tier)
- Create `requirements.txt` for Spaces
- Deploy Streamlit app
- Test live URL

**Estimated Time:** 1 day

---

#### 2. Documentation
**Status:** âš ï¸ **PARTIAL**

**What Exists:**
- âœ… Data pipeline README
- âœ… Analytics guide (basic)
- âœ… Project structure docs

**What's Missing:**
- âŒ Spatial analysis implementation guide
- âŒ Temporal analysis implementation guide
- âŒ 57 questions mapping document
- âŒ 22 gaps implementation mapping
- âŒ User guide for dashboard
- âŒ API documentation
- âŒ Demo video/screenshots

**Estimated Time:** 2-3 days

---

#### 3. Portfolio Materials
**Status:** âŒ **NOT CREATED**

**Need to Create:**
- âŒ 2-minute demo video
- âŒ Dashboard screenshots (10-15 images)
- âŒ One-page project summary PDF
- âŒ Technical blog post (Medium/LinkedIn)
- âŒ GitHub README with badges
- âŒ Interview talking points document

**Estimated Time:** 2 days

---

## ğŸ“… PHASE 1 TACTICAL IMPLEMENTATION PLAN (Spatial Analytics - Days 1-10)

### Overview
**Goal:** Complete all 46 spatial questions + 16 consulting gaps + ML models + dashboard deployment

**Output:** Fully functional spatial analytics module deployed to Hugging Face Spaces

**Timeline:** 7-10 days of focused development

---

### DAY 1: Spatial Metrics Computation (Core Analytics)

**Goal:** Answer all 46 spatial questions systematically

**Tasks:**

**Morning (4 hours):**
```bash
# 1. Create analysis directory structure
mkdir -p analysis/spatial/{outputs,visualizations,data}

# 2. Create main metrics computation script
touch analysis/spatial/01_compute_spatial_metrics.py
```

**Script to Build:** `analysis/spatial/01_compute_spatial_metrics.py`
```python
"""
Compute answers to all 46 spatial questions
Output: spatial_questions_answers.json with structured results
"""

import pandas as pd
import numpy as np
from scipy.stats import pearsonr
import json

def compute_category_a_coverage_accessibility():
    """Category A: 8 questions on coverage & accessibility"""
    # Load data
    lsoa_data = pd.read_parquet('data/processed/lsoa_integrated.parquet')

    results = {}

    # A1: Regions with highest routes per capita
    results['A1'] = {
        'question': 'Which regions have highest number of bus routes per capita?',
        'answer': lsoa_data.groupby('region').apply(
            lambda x: x['routes'].sum() / x['population'].sum() * 100000
        ).sort_values(ascending=False).to_dict(),
        'visualization': 'bar_chart_routes_per_capita.png'
    }

    # A2: Regions with lowest stops per 1000 residents
    # ... [implement remaining 7 questions]

    return results

def compute_all_spatial_questions():
    """Main function: compute all 46 spatial questions"""
    all_results = {}

    # Category A: Coverage & Accessibility (8 questions)
    all_results['category_a'] = compute_category_a_coverage_accessibility()

    # Category B: Service Frequency (5 spatial questions)
    all_results['category_b'] = compute_category_b_service_frequency()

    # Category C: Route Characteristics (7 questions)
    all_results['category_c'] = compute_category_c_route_characteristics()

    # Category D: Socio-Economic Correlations (8 questions)
    all_results['category_d'] = compute_category_d_socioeconomic()

    # Category F: Equity & Policy (6 spatial questions)
    all_results['category_f'] = compute_category_f_equity_policy()

    # Category G: Advanced Insights (5 spatial questions)
    all_results['category_g'] = compute_category_g_advanced_insights()

    # Category H: Accessibility Deep Dive (4 questions)
    all_results['category_h'] = compute_category_h_accessibility()

    # Category I: Economic Impact (3 questions)
    all_results['category_i'] = compute_category_i_economic_impact()

    return all_results

if __name__ == '__main__':
    print("ğŸ”„ Computing answers to 46 spatial questions...")
    results = compute_all_spatial_questions()

    # Save results
    with open('analysis/spatial/outputs/spatial_answers.json', 'w') as f:
        json.dump(results, f, indent=2)

    print(f"âœ… Computed {sum(len(v) for v in results.values())} question answers")
```

**Afternoon (4 hours):**
```bash
# 3. Run metrics computation
python analysis/spatial/01_compute_spatial_metrics.py

# 4. Verify outputs
ls -lh analysis/spatial/outputs/
cat analysis/spatial/outputs/spatial_answers.json | jq '.category_a | keys'

# 5. Generate visualizations for top 10 questions
python analysis/spatial/generate_visualizations.py
```

**Evening:**
- Review results for accuracy
- Document any data quality issues
- Plan Day 2 ML model training

**Deliverables:**
- âœ… `spatial_answers.json` with 46 question answers
- âœ… 20+ visualizations (bar charts, scatter plots, heatmaps)
- âœ… Summary statistics report

---

### DAY 2: ML Model Training (Route Clustering + Anomaly Detection)

**Goal:** Train 3 ML models for spatial analysis

**Morning (4 hours):**
```bash
# 1. Install ML dependencies
pip install sentence-transformers hdbscan umap-learn scikit-learn

# 2. Create ML training script
touch analysis/spatial/02_train_ml_models.py
```

**Script to Build:** `analysis/spatial/02_train_ml_models.py`
```python
"""
Train 3 spatial ML models:
1. Route clustering (Sentence Transformers + HDBSCAN)
2. Underserved area detection (Isolation Forest)
3. Coverage prediction (Random Forest)
"""

from sentence_transformers import SentenceTransformer
from hdbscan import HDBSCAN
from sklearn.ensemble import IsolationForest, RandomForestRegressor
import joblib

def train_route_clustering():
    """Model 1: Route clustering via embeddings"""
    # Load routes
    routes = pd.read_parquet('data/processed/routes_combined.parquet')

    # Create route descriptions
    routes['description'] = routes.apply(lambda r:
        f"Route {r['route_name']} operated by {r['operator']}. "
        f"Serves {r['stops_count']} stops across {r['region']}.", axis=1)

    # Generate embeddings
    model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')
    embeddings = model.encode(routes['description'].tolist(), show_progress_bar=True)

    # Cluster
    clusterer = HDBSCAN(min_cluster_size=5, metric='euclidean')
    routes['cluster'] = clusterer.fit_predict(embeddings)

    # Save
    joblib.dump(clusterer, 'analysis/spatial/models/route_clusterer.pkl')
    routes.to_parquet('analysis/spatial/outputs/routes_clustered.parquet')

    print(f"âœ… Route clustering: {len(routes['cluster'].unique())} clusters found")
    return clusterer, routes

def train_anomaly_detection():
    """Model 2: Spatial anomaly detection (underserved areas)"""
    lsoa_data = pd.read_parquet('data/processed/lsoa_integrated.parquet')

    # Features
    features = ['population', 'bus_stops', 'routes', 'imd_score',
                'unemployment', 'elderly_pct']
    X = lsoa_data[features].fillna(lsoa_data[features].median())

    # Standardize
    from sklearn.preprocessing import StandardScaler
    scaler = StandardScaler()
    X_scaled = scaler.fit_transform(X)

    # Train Isolation Forest
    iso_forest = IsolationForest(contamination=0.05, random_state=42)
    lsoa_data['is_anomaly'] = iso_forest.fit_predict(X_scaled)

    # Save
    joblib.dump(iso_forest, 'analysis/spatial/models/anomaly_detector.pkl')
    joblib.dump(scaler, 'analysis/spatial/models/scaler.pkl')

    underserved = lsoa_data[lsoa_data['is_anomaly'] == -1]
    print(f"âœ… Anomaly detection: {len(underserved)} underserved LSOAs identified")
    return iso_forest, underserved

def train_coverage_prediction():
    """Model 3: Coverage prediction (Random Forest)"""
    lsoa_data = pd.read_parquet('data/processed/lsoa_integrated.parquet')

    # Features & target
    features = ['population', 'imd_score', 'unemployment', 'elderly_pct', 'area_km2']
    X = lsoa_data[features]
    y = lsoa_data['bus_stops']

    # Train
    from sklearn.model_selection import train_test_split
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

    rf = RandomForestRegressor(n_estimators=100, random_state=42)
    rf.fit(X_train, y_train)

    # Evaluate
    from sklearn.metrics import r2_score, mean_absolute_error
    y_pred = rf.predict(X_test)
    r2 = r2_score(y_test, y_pred)
    mae = mean_absolute_error(y_test, y_pred)

    # Save
    joblib.dump(rf, 'analysis/spatial/models/coverage_predictor.pkl')

    print(f"âœ… Coverage prediction: RÂ²={r2:.3f}, MAE={mae:.1f} stops")
    return rf

if __name__ == '__main__':
    print("ğŸ”„ Training 3 spatial ML models...")

    # Train all models
    route_clusterer, routes_clustered = train_route_clustering()
    anomaly_detector, underserved = train_anomaly_detection()
    coverage_predictor = train_coverage_prediction()

    print("âœ… All models trained and saved!")
```

**Afternoon (4 hours):**
```bash
# 3. Run ML training
python analysis/spatial/02_train_ml_models.py

# 4. Verify models
ls -lh analysis/spatial/models/
# Should see: route_clusterer.pkl, anomaly_detector.pkl, coverage_predictor.pkl

# 5. Test model loading
python -c "import joblib; model = joblib.load('analysis/spatial/models/route_clusterer.pkl'); print('âœ… Model loads OK')"
```

**Deliverables:**
- âœ… 3 trained ML models (pickled)
- âœ… Route clustering results (parquet)
- âœ… Underserved areas list
- âœ… Model evaluation metrics

---

### DAY 3: Policy Recommendations Engine

**Goal:** Generate prescriptive recommendations using ML outputs

**Tasks:**
```bash
# 1. Create recommendations script
touch analysis/spatial/03_generate_recommendations.py
```

**Script:** `analysis/spatial/03_generate_recommendations.py` (implement using Gap 15 code from document)

**Deliverables:**
- âœ… Recommendations database (JSON)
- âœ… Priority investment map
- âœ… ROI calculations for top 20 interventions

---

### DAY 4-5: Dashboard Development (5 Spatial Pages)

**Goal:** Build interactive Streamlit dashboard with 5 tabs

**Day 4 Morning:**
```bash
# 1. Create dashboard structure
mkdir -p dashboard/pages dashboard/modules/spatial dashboard/utils

# 2. Create main spatial analytics page
touch dashboard/pages/02_ğŸ“_Spatial_Analytics.py

# 3. Create module files
touch dashboard/modules/spatial/{coverage,routes,equity,ml_insights,recommendations}.py
```

**Day 4 Afternoon - Day 5:**
Implement 5 spatial dashboard tabs (code examples in Gaps section of document)

**Deliverables:**
- âœ… 5 functional dashboard tabs
- âœ… Interactive filters (region, IMD, unemployment)
- âœ… Folium maps with multiple layers
- âœ… ML insights visualization

---

### DAY 6-7: Questions Explorer + Consulting Gaps Pages

**Goal:** Build showcase pages for 57 questions and 22 gaps

**Tasks:**
```bash
# Day 6: Questions Explorer
touch dashboard/pages/03_ğŸ“‹_Questions_Explorer.py
python scripts/build_qa_database.py  # Pre-compute Q&A

# Day 7: Consulting Gaps showcase
touch dashboard/pages/04_ğŸ¯_Consulting_Gaps.py
```

**Deliverables:**
- âœ… Searchable questions database
- âœ… Category filtering
- âœ… Side-by-side gap comparison
- âœ… Live capability demos

---

### DAY 8: NLP Q&A System

**Goal:** Natural language query interface

**Tasks:**
```bash
# 1. Create Q&A page
touch dashboard/pages/05_ğŸ’¬_Ask_Questions.py

# 2. Build semantic search
python scripts/build_semantic_qa.py
```

**Deliverables:**
- âœ… Semantic search Q&A
- âœ… Answer with sources
- âœ… Follow-up suggestions

---

### DAY 9: Deployment Preparation

**Goal:** Optimize data and prepare for Hugging Face deployment

**Tasks:**
```bash
# 1. Create deployment scripts
touch scripts/{prepare_deployment_data.py,precompute_answers.py,check_deployment_size.sh}

# 2. Run optimization
python scripts/prepare_deployment_data.py
python scripts/precompute_answers.py

# 3. Verify size
bash scripts/check_deployment_size.sh
# Expected: ~300 MB (under 1 GB limit âœ…)

# 4. Create deployment folder
mkdir deployment
cp -r dashboard/* deployment/
cp analysis/spatial/outputs/* deployment/data/
cp analysis/spatial/models/* deployment/models/
```

**Deliverables:**
- âœ… Optimized deployment data (<1 GB)
- âœ… Pre-computed answers
- âœ… Cached visualizations
- âœ… Deployment folder ready

---

### DAY 10: Deploy to Hugging Face Spaces

**Goal:** Live deployment and testing

**Morning:**
```bash
# 1. Install Hugging Face CLI
pip install huggingface_hub

# 2. Login
huggingface-cli login

# 3. Create Space
huggingface-cli repo create uk-bus-analytics --type space --space_sdk streamlit

# 4. Clone and deploy
git clone https://huggingface.co/spaces/{username}/uk-bus-analytics
cd uk-bus-analytics
cp -r ../deployment/* .
git add .
git commit -m "Deploy Spatial Analytics Module v1.0"
git push
```

**Afternoon:**
- Test live URL
- Fix any deployment issues
- Create README for Space
- Take screenshots for portfolio

**Deliverables:**
- âœ… Live deployed dashboard
- âœ… Public URL working
- âœ… All features functional
- âœ… Documentation complete

---

## ğŸ“… IMPLEMENTATION TIMELINE

### Week 1: Spatial Analytics (Days 1-7)
| Day | Tasks | Deliverable |
|-----|-------|-------------|
| 1 | Compute 46 spatial question answers | All spatial questions answered |
| 2 | Train 3 ML models (clustering, anomaly, prediction) | ML models saved |
| 3-4 | Build spatial dashboard pages (5 tabs) | Spatial module functional |
| 5 | Integration & testing | End-to-end spatial workflow |
| 6 | Bug fixes & polish | Production-ready spatial module |
| 7 | Documentation (spatial) | Spatial docs complete |

**Week 1 Goal:** âœ… Fully functional Spatial Analytics Module answering 46 questions with 16 consulting gaps filled

---

### Week 2: Temporal Analytics Setup (Days 8-14)
| Day | Tasks | Deliverable |
|-----|-------|-------------|
| 8 | Download Zenodo (19.5 GB) + missing demographics | All historical data downloaded |
| 9 | Process Zenodo archive â†’ time-series format | 104 snapshots parsed |
| 10 | Aggregate to monthly LSOA metrics | Time-series dataframe ready |
| 11 | Train Prophet forecasting models | Forecasts generated |
| 12 | Temporal anomaly detection + trends | Anomalies/trends identified |
| 13-14 | Build temporal dashboard pages (4 tabs) | Temporal module functional |

**Week 2 Goal:** âš ï¸ Temporal demo module with 2021-2023 proof-of-concept

---

### Week 3: Integration & Deployment (Days 15-21)
| Day | Tasks | Deliverable |
|-----|-------|-------------|
| 15 | Integrate both modules in single app | Seamless navigation |
| 16 | Build 57 Questions Explorer page | All questions searchable |
| 17 | Build Consulting Gaps showcase page | 22 capabilities demonstrated |
| 18 | Build Natural Language Q&A page | NLP interface working |
| 19 | Deploy to Hugging Face Spaces | Live URL accessible |
| 20 | Complete documentation | All docs finished |
| 21 | Create portfolio materials | Portfolio-ready package |

**Week 3 Goal:** âœ… Complete deployed application with documentation

---

## ğŸ¯ SUCCESS METRICS

### Spatial Module (Week 1)
- âœ… 46 questions answered with visualizations
- âœ… 3 ML models trained and integrated
- âœ… 16 consulting gaps demonstrated
- âœ… 5 dashboard pages functional
- âœ… Sub-2-second page load times

### Temporal Module (Week 2)
- âœ… 2.5 years historical data processed (2021-2023)
- âœ… Prophet forecasting working for 10+ LSOAs
- âœ… Temporal anomalies identified
- âœ… 11 temporal questions answered
- âœ… 4 dashboard pages functional

### Complete Application (Week 3)
- âœ… All 57 questions accessible
- âœ… 22 consulting gaps showcased
- âœ… NLP Q&A system functional
- âœ… Deployed on Hugging Face Spaces
- âœ… Complete documentation
- âœ… Portfolio materials ready

---

## ğŸ“¦ MISSING DATA DOWNLOAD PLAN

### Priority 1: Essential Historical Demographics

**Task 1.1: Population Mid-Year Estimates (2022, 2023)**
```bash
# Script: scripts/download_historical_demographics.py

from utils.api_client import NomisClient

nomis = NomisClient()

# Download 2022 population
pop_2022 = nomis.get_dataset(
    dataset='NM_2002_1',  # Population estimates
    geography='TYPE464',   # LSOA level
    date='2022'
)
pop_2022.to_csv('data/raw/demographics/population_2022.csv')

# Download 2023 population
pop_2023 = nomis.get_dataset(
    dataset='NM_2002_1',
    geography='TYPE464',
    date='2023'
)
pop_2023.to_csv('data/raw/demographics/population_2023.csv')

print("âœ… Downloaded population 2022, 2023")
```

**Status:** âŒ Need to run
**Time:** 15-20 minutes
**Size:** ~100 MB total

---

**Task 1.2: Historical Unemployment (2021, 2022, 2023)**
```bash
# Continued in same script

for year in [2021, 2022, 2023]:
    unemployment = nomis.get_dataset(
        dataset='NM_162_1',  # Claimant count
        geography='TYPE464',
        date=str(year)
    )
    unemployment.to_csv(f'data/raw/demographics/unemployment_{year}.csv')
    print(f"âœ… Downloaded unemployment {year}")
```

**Status:** âŒ Need to run
**Time:** 10-15 minutes
**Size:** ~60 MB total

---

**Task 1.3: Check Schools Historical Availability**
```bash
# Script: scripts/check_schools_historical.py

import requests

years = [2021, 2022, 2023]
base_url = "https://get-information-schools.service.gov.uk/Downloads"

for year in years:
    # Check if historical snapshot exists
    # Pattern: edubasealldata{YYYYMMDD}.csv
    # Try end of year dates: Dec 31
    url = f"{base_url}/edubasealldata{year}1231.csv"
    response = requests.head(url)

    if response.status_code == 200:
        print(f"âœ… Schools {year} available: {url}")
        # Download if available
    else:
        print(f"âŒ Schools {year} NOT available")
        print(f"   Will use 2025 schools data for all years (acceptable)")
```

**Status:** âŒ Need to check
**Time:** 5 minutes
**Decision:** If not available, use schools_2025.csv for all years (document this)

---

### Priority 2: Transport Historical Data

**Task 2.1: Download Zenodo Archive**
```bash
# Script: scripts/download_zenodo.sh

#!/bin/bash
set -e

echo "ğŸ“¥ Downloading Zenodo BODS Historical Archive (19.5 GB)..."
mkdir -p data/temporal/historical
cd data/temporal/historical

wget https://zenodo.org/records/14779119/files/bods_archive_jun2023.zip \
    --progress=bar:force \
    --continue

echo "ğŸ“‚ Extracting archive..."
unzip -q bods_archive_jun2023.zip

echo "âœ… Zenodo archive ready!"
ls -lh
```

**Status:** âŒ Need to run
**Time:** 30-60 min download + 5-10 min extraction
**Size:** 19.5 GB

---

## ğŸš€ IMMEDIATE NEXT STEPS (This Week)

### Day 1 (Today): Data Download
1. âœ… Run `scripts/download_historical_demographics.py` (download pop + unemployment 2021-2023)
2. âœ… Run `scripts/check_schools_historical.py` (check if schools 2021-2023 available)
3. âœ… Run `scripts/download_zenodo.sh` (download transport 2021-2023)
4. âœ… Verify all downloads successful

**Time:** 1-2 hours
**Output:** All historical data ready in `data/raw/`

---

### Day 2: Spatial Metrics Computation
1. âœ… Create `analysis/spatial/01_compute_spatial_metrics.py`
2. âœ… Load Oct 2025 data + demographics
3. âœ… Compute answers to 46 spatial questions
4. âœ… Save results to `data/processed/spatial/spatial_questions_answers.json`

**Time:** 4-6 hours
**Output:** 46 spatial questions answered

---

### Day 3-7: Continue Week 1 Timeline
Follow Week 1 plan as outlined above.

---

## ğŸ“Š CURRENT FILE STATUS

### What We Have (Files/Code)
```
âœ… data_pipeline/01_data_ingestion.py
âœ… data_pipeline/02_data_processing.py
âœ… data_pipeline/03_data_validation.py
âœ… data_pipeline/04_descriptive_analytics.py
âœ… analytics/descriptive_analysis.py
âœ… analytics/05_correlation_analysis.py
âœ… dashboard/app.py (basic skeleton)
âœ… config/settings.py
âœ… utils/api_client.py
âœ… utils/gtfs_parser.py
âœ… utils/geographic_data_client.py
```

### What We Need to Build (Files/Code)
```
âŒ analysis/spatial/01_compute_spatial_metrics.py
âŒ analysis/spatial/02_train_ml_models.py
âŒ analysis/spatial/03_generate_recommendations.py
âŒ analysis/temporal/01_process_zenodo_archive.py
âŒ analysis/temporal/02_create_timeseries.py
âŒ analysis/temporal/03_train_forecasting_models.py
âŒ analysis/temporal/04_detect_anomalies.py
âŒ dashboard/pages/02_ğŸ“_Spatial_Analytics.py
âŒ dashboard/pages/03_â±ï¸_Temporal_Analytics.py
âŒ dashboard/pages/04_ğŸ“‹_Questions_Explorer.py
âŒ dashboard/pages/05_ğŸ¯_Consulting_Gaps.py
âŒ dashboard/pages/06_ğŸ’¬_Ask_Questions.py
âŒ dashboard/modules/spatial/* (5 modules)
âŒ dashboard/modules/temporal/* (4 modules)
âŒ scripts/download_zenodo.sh
âŒ scripts/download_historical_demographics.py
âŒ scripts/check_schools_historical.py
```

---

## ğŸ’¡ QUESTIONS & DECISIONS NEEDED

### Question 1: Schools Historical Data
**If schools 2021-2023 NOT available from GIAS:**
- **Option A:** Use schools_2025.csv for all years (2021, 2022, 2023)
- **Option B:** Skip school-related temporal analysis
- **Recommendation:** Option A (schools change slowly, acceptable methodology)

**Your Decision:** _____________

---

### Question 2: Temporal Analysis Scope
**How deep should temporal analysis go?**
- **Option A:** Full (Prophet per LSOA, 7,696 models) - computationally intensive
- **Option B:** Regional (Prophet per region, 9 models) - faster, still valuable
- **Recommendation:** Start with Option B (regional), add LSOA-level if time permits

**Your Decision:** _____________

---

### Question 3: Deployment Target
**Where to deploy?**
- **Option A:** Hugging Face Spaces (free, easy, designed for ML apps)
- **Option B:** Streamlit Cloud (free, simple, but limited resources)
- **Option C:** Heroku/AWS (more control, but costs $$)
- **Recommendation:** Option A (Hugging Face Spaces)

**Your Decision:** _____________

---

## âœ… APPROVAL CHECKLIST

Before proceeding, confirm:

- [ ] **Data Download Plan Clear:** Understand what data to download (demographics 2021-2023, Zenodo)
- [ ] **Current vs To-Do Clear:** Understand what's built vs what needs building
- [ ] **Timeline Realistic:** 3 weeks (Spatial Week 1, Temporal Week 2, Integration Week 3)
- [ ] **Missing Data Strategy:** Accept using schools_2025 for all years if historical unavailable
- [ ] **Implementation Level:** Step-by-step code examples are clear enough to implement

---

**STATUS:** Awaiting your approval to proceed with implementation! ğŸš€
